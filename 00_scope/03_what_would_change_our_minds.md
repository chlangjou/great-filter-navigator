## Document Summary

**Purpose**: Establish explicit falsifiability standards and conditions for revising claims across the GFN.  
**Audience**: All contributors; essential reference for entry validation.  
**Status**: [Consensus] - Core corrigibility framework.

## Related Documents

- **Prerequisites**: `00_epistemic_status.md` - Foundational principle that "nothing is unfalsifiable."
- **Used by**: `02_entry_template.md` - Section 9 of all entries must reference this document.
- **Validates**: All hypothesis and response entries in `10_hypotheses/` and `20_mechanisms/`.
- **Reference**: `04_adversarial_scenarios.md` - Defensive mechanisms include resistance to bad-faith falsification claims.

---

# What Would Change Our Minds

This document records **conditions under which claims, assumptions, or organizing choices in this repository should be revised, weakened, or abandoned**.

Its purpose is to make epistemic commitments explicit and to prevent the gradual hardening of speculative ideas into unquestioned beliefs.

Nothing in this repository is treated as unfalsifiable.

---

## Why this document exists

Long-horizon risk analysis is especially vulnerable to:
- motivated reasoning,
- narrative lock-in,
- over-weighting elegant explanations,
- and under-weighting disconfirming evidence.

By explicitly stating what would change our minds, we aim to:
- reduce overconfidence,
- surface hidden assumptions,
- and keep the repository corrigible over time.

---

## Scope of revision

Revisions may apply to:
- individual risk entries,
- response patterns,
- modeling assumptions,
- or the overall taxonomy itself.

Revision does **not** imply failure; it is the expected outcome of engaging with uncertainty.

---

## Examples of mind-changing evidence or arguments

The following are **illustrative, not exhaustive**, examples of what could prompt significant updates.

### 1. Empirical disconfirmation

Examples:
- Reliable historical or experimental evidence showing that a proposed risk mechanism does not scale as assumed.
- Observed cases where a hypothesized failure mode repeatedly fails to materialize despite favorable conditions.
- Data indicating that proposed response patterns systematically backfire or introduce larger secondary risks.

---

### 2. Strong alternative explanations

Examples:
- A simpler or more general model that explains the same phenomena with fewer assumptions.
- A reframing that collapses multiple distinct-looking risks into a single underlying mechanism.
- Demonstrations that an apparent risk is better explained by coordination or incentive failures already well-understood.

---

### 3. Robust counterexamples

Examples:
- Real-world systems that remain stable despite violating assumptions thought to be necessary for safety.
- Historical cases where irreversible-looking lock-in was successfully reversed without catastrophic cost.
- Agent designs or governance structures that behave safely without relying on assumed constraints.

---

### 4. Theoretical constraints

Examples:
- Impossibility results or formal arguments showing that certain response patterns cannot work as intended.
- Decision-theoretic results that undermine key intuitions about incentives, timing, or risk sensitivity.
- Proofs that certain classes of uncertainty cannot be maintained or operationalized by bounded agents.

---

### 5. Better decomposition of uncertainty

Examples:
- Clear separation of what was previously conflated (e.g., empirical uncertainty vs normative disagreement).
- Identification of hidden variables that explain apparent trade-offs.
- Recognition that a risk previously treated as unitary is actually composed of independent sub-risks.

---

## Signs that an entry should be weakened or deprecated

An entry should be reconsidered if:

- Its assumptions are repeatedly violated in realistic scenarios.
- Its failure modes dominate its potential benefits.
- It adds complexity without improving predictive or decision-relevant power.
- It survives only by vague phrasing or unfalsifiable claims.

Deprecation does not require deletion; annotations and versioning are preferred.

---

## Process expectations

When updating beliefs:

- Prefer **explicit revisions** over silent edits.
- Preserve earlier reasoning when possible, with annotations explaining why it is no longer endorsed.
- Treat disagreement as information, not noise.

Contributors are encouraged to include a short section in major entries titled:
> *"What would change my mind"*

---

## Summary

This repository treats **being wrong as normal** and **updating as success**.

Claims here are provisional, conditional, and subject to revision as better arguments, evidence, or models emerge.