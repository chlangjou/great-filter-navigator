## Document Summary

**Purpose**: Define the categorization and classification logic for all entries in the Great Filter Navigator.  
**Audience**: Contributors, curators, and automated indexing systems.  
**Status**: [Consensus] - Operational classification schema.

## Related Documents

- **Prerequisites**: `10_epistemic_status.md` - Foundational epistemic framework.
- **Used by**: `30_entry_template.md` - Templates incorporate these classification tags.
- **Related**: `40_what_would_change_our_minds.md` - Framework itself is subject to revision.
- **Reference**: All risk entries in `10_hypotheses/` and responses in `20_mechanisms/`.

---

# Taxonomy and Classification Framework

## Purpose
This document defines the categorization logic for the Great Filter Navigator. It ensures that all entries, hypotheses, and interventions are indexed consistently to allow for efficient navigation by both human collaborators and AI agents.

## 1. Primary Structural Layers (Folder Alignment)
The repository is organized into functional layers reflecting the lifecycle of risk management:

* **00_Scope**: Meta-frameworks, templates, and epistemic standards.
* **10_Hypotheses**: The "Problem Space." Mapping specific Great Filter threats and AI alignment failures.
* **20_Mechanisms**: The "Solution Space." Technical, social, and philosophical countermeasures.
* **30_Observatory**: Real-time monitoring, data feeds, and empirical evidence.
* **40_Analysis_Logic**: Experimental models, simulations, and unverified drafts.

## 2. Risk Categorization (The 10_Hypotheses Schema)
We classify risks based on their origin and nature, following the A-B-C framework:

### Category A: Internal Cognitive Risks (The "Self")
* **A1: Value Alignment**: Mismatch between human values and AI objectives.
* **A2: Agency Loss**: Gradual erosion of human decision-making power to automated systems.
* **A3: Epistemic Decay**: Breakdown of shared reality due to AI-generated misinformation.

### Category B: External Systemic Risks (The "Environment")
* **B1: Resource Exhaustion**: Competitive races leading to depletion of critical assets.
* **B2: Kinetic Escalation**: AI-driven conflict or automated warfare.
* **B3: Biological/Ecological Collapse**: Synthetic biology or environmental feedback loops.

### Category C: Structural & Coordination Risks (The "Connection")
* **C1: Multi-polar Traps**: Game-theoretical failures where individual rational choices lead to collective ruin.
* **C2: Governance Failure**: Inability of institutional frameworks to keep pace with technological acceleration.

## 3. Epistemic Tagging (The Confidence Scale)
Every entry must be tagged with a status defined in `00_epistemic_status.md`:
* `[Speculative]`: Early-stage ideas or "What-if" scenarios.
* `[Theoretical]`: Robust logical frameworks lacking empirical data.
* `[Empirical]`: Supported by historical data or current observations.
* `[Consensus]`: Widely accepted by the alignment and safety community.

## 4. Intervention Mapping (The 20_Mechanisms Schema)
Interventions are categorized by their point of impact:
* **Technical**: Hard-coded safety, interpretability, and formal verification.
* **Institutional**: Treaties, monitoring regimes, and global governance.
* **Cognitive**: Tools for enhancing human intelligence and group coordination.
* **Infrastructural**: Hardening the "Internet of Sovereignty" and physical fail-safes.

## 5. Cross-Cutting Tags
To improve searchability, use the following functional tags:
* `#existential-risk`: Threats to the survival of the species.
* `#s-risk`: Risks of suffering (e.g., permanent dystopian states).
* `#near-term`: Urgent issues (0-5 years).
* `#long-term`: Strategic concerns (5+ years).