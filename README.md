# Great Filter Navigator (GFN)

> **"The Great Filter is not a wall we hit, but a series of choices we make. AI is both the storm we weather and the compass we use to find the shore."**

## ðŸŒŒ Overview
The **Great Filter Navigator (GFN)** is an open-source framework designed to navigate the existential risks posed by Artificial Intelligence and other civilizational-scale threats. 

Within the context of the **Great Filter Hypothesis**, we assume that civilizations face critical evolutionary bottlenecks that lead to extinction. Our goal is to treat AI alignment not as a static technical problem, but as a dynamic steering challenge. This repository serves as the "Bridge" of a civilizational ship, mapping risks, monitoring thresholds, and deploying interventions.

---

## ðŸ§­ The Navigation Loop (Core Logic)
To effectively steer civilization away from "Filters," GFN operates on a recursive feedback loop. This structure ensures that every theory leads to a metric, every metric leads to a solution, and every solution is grounded in data.

1.  **Hypothesize ([10_hypotheses](./10_hypotheses/))**: Identify specific Great Filter failure modes (The Minefield).
2.  **Monitor ([20_dashboard](./20_dashboard/))**: Define measurable indicators and tripwires for those filters (The Radar).
3.  **Intervene ([30_mechanisms](./30_mechanisms/))**: Develop technical and social protocols to respond when thresholds are breached (The Engines).
4.  **Observe ([40_observatory](./40_observatory/))**: Collect real-time evidence to validate hypotheses and update the dashboard (The Sensors).

---

## ðŸ“‚ Repository Architecture

### [00_scope](./00_scope/) | The Compass
This directory contains the meta-framework of the project.
* **Taxonomy**: Standardized classification for risks and solutions.
* **Epistemic Status**: Truth-claims and confidence levels to prevent information pollution.
* **Adversarial Scenarios**: Pre-mortems on how the Navigator itself could be compromised.

### [10_hypotheses](./10_hypotheses/) | The Minefield
A library of specific Great Filter scenarios and AI alignment failure modes.
* *Focus*: "What could go wrong?" (e.g., Agency loss, Value misalignment, Multi-polar traps).

### [20_dashboard](./20_dashboard/) | The Radar
The primary interface for situational awareness.
* *Focus*: "How do we know we are in danger?" 
* *Content*: Metrics, early warning signals, and "tripwires" (thresholds that trigger emergency action).

### [30_mechanisms](./30_mechanisms/) | The Engines
The "Solution Space" containing protocols to mitigate or avoid the Filters.
* *Focus*: "How do we steer away?"
* *Content*: Technical alignment tools, coordination treaties, and cognitive sovereignty defenses.

### [40_observatory](./40_observatory/) | The Sensors
Raw data feeds and empirical logs.
* *Focus*: "What is actually happening?"
* *Content*: Links to real-time monitoring tools, compute-usage logs, and social entropy data.

---

## ðŸ›  For Contributors (Human & AI)

### Epistemic Responsibility
Due to the high-stakes nature of AI alignment, all contributions must follow the **Epistemic Standards** defined in `00_scope`. We value intellectual honesty over certainty. If a theory is speculative, tag it as `[Speculative]`.

### AI Agent Integration
This repository is optimized for AI thought partners. 
- Use the `entry_template.md` for all new submissions.
- Ensure all cross-references between `Hypotheses` and `Mechanisms` are explicitly linked to maintain the knowledge graph integrity.

### How to Help
1. **Scout**: Add new failure modes to `10_hypotheses`.
2. **Monitor**: Propose new metrics for `20_dashboard`.
3. **Engineer**: Build defense protocols in `30_mechanisms`.
4. **Report**: Log empirical observations in `40_observatory`.

---

## ðŸ“œ License & Governance
The Great Filter Navigator is a public good. It is governed by the principle of **Cognitive Sovereignty**â€”ensuring that the tools for human survival remain transparent, decentralized, and accessible to all.

*"Steer well. There is no second attempt."*
