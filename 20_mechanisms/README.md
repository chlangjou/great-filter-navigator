# 20_dashboard: Risk Indicators & Early Warning Systems

## Overview
The Dashboard is the "Radar" of the Great Filter Navigator. Its purpose is to define, track, and visualize the specific indicators that suggest a Great Filter event or a significant AI alignment failure is approaching. 

By establishing **Tripwires** and **Metrics**, we aim to move from speculative fear to data-driven situational awareness.

## Core Monitoring Domains

### 1. Technical & Capability Overhang (Technical Indicators)
Monitoring the "intelligence explosion" and the emergence of unaligned capabilities.
* **Compute Scaling**: Tracking the total FLOPs used in state-of-the-art training runs.
* **Capability Evals**: Indicators of deception, self-proliferation, or advanced recursive self-improvement.
* **Alignment Tax**: Measuring the performance gap between aligned and unaligned models.

### 2. Epistemic & Social Stability (Cognitive Indicators)
Monitoring the health of the "Internet of Sovereignty" and collective human intelligence.
* **Information Entropy**: Tracking the ratio of synthetic vs. human-generated content in public discourse.
* **Institutional Trust**: Metrics on the breakdown of shared reality and consensus-building capabilities.
* **Polarization Index**: Early warning for AI-accelerated social fragmentation.

### 3. Strategic & Geopolitical Tension (Structural Indicators)
Monitoring the "Multi-polar Traps" and the race to the bottom.
* **Compute Concentration**: Tracking the geographic and corporate distribution of high-end AI hardware.
* **Regulatory Drift**: Indicators of "safety-washing" or the abandonment of safety protocols in competitive races.
* **Resource Scarcity**: Monitoring critical supply chains (e.g., HBM, advanced lithography) as potential flashpoints.

### 4. Biological & Existential Thresholds (Environmental Indicators)
Monitoring physical risks that could trigger a Great Filter event.
* **Biosynthesis Capability**: Monitoring the accessibility of DNA synthesis tools and pathogen blueprints.
* **Autonomous Kinetic Systems**: Tracking the deployment of AI in lethal autonomous weapons (LAWS).

## The Methodology: Tripwires and Thresholds
Every indicator in this directory should attempt to define:
1. **Green (Baseline)**: Normal technological/social progression.
2. **Yellow (Caution)**: Significant deviation; requires increased oversight and "Adversarial Scenarios" review.
3. **Red (Tripwire)**: Critical threshold reached; immediate activation of `Mechanisms` (from the next layer) is required.



## How to Add an Indicator
1. **Link to Hypothesis**: Every indicator must monitor at least one threat defined in `10_hypotheses`.
2. **Define the Metric**: What exactly are we measuring? (e.g., $/GFLOP, Misinfo-rate).
3. **Identify Data Sources**: Where can the `Observatory` (30_) pull real-time data from?
